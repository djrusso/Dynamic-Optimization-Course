# Dynamic programming and Optimal Control  

## Course Information
Schedule: Winter 2020, Mondays 2:30pm - 5:45pm

Professor: Daniel Russo (djr2174@gsb.columbia.edu)

TAs: Jalaj Bhandari and Chao Qin 

Course Number: B9120-001


## Course description and outline:

This course serves as an advanced introduction to dynamic programming and optimal control. The first part of the course will cover  problem formulation and problem specific solution ideas arising in cannonincal control problems. The second part of the course covers algorithms for computing optimal (or effective) policies. 


* Problem formulations
  * Finite horizon
  * Infinite horizon discounted
  * Continuous-time discrete-state problems
  * Brief overview of average cost and indefinite horizon problems. 
* Problem specific ideas
  * Myopic policies in optimal stopping 
  * Base-stock and (s,S) policies in inventory control
  * Linear policies in linear quadratic control
  * Kalman filtering and certainty equivalent control
  * Interchange arguments and optimality of index policies in multi-armed bandits and control of queues. 
* Exact algorithms for problems with tractable state-spaces
  * Value Iterations
  * Policy Iteration
  * Linear Programming
* Foundations of reinforcement learning and approximate dynamic programming. 
  * Asynchronous value iteration and optimistic variants   
  * Convergence of policy gradient methods 
  * Convergence of TD-learning 
  * Policy chattering in Q-learning 
  * Approximate linear programming


## Prerequisites
Markov chains, linear programming; mathematical maturity (this is a doctoral course). 

